{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train darknet with custom dataset\n",
    "\n",
    "this notebook demonstrates how to train darknet with following custom dataset\n",
    "\n",
    "https://www.kaggle.com/andrewmvd/face-mask-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download custom data\n",
    "\n",
    "download kaggle api token (kaggle.json) from kaggle account and install kaggle utility. Seel this [link](https://www.kaggle.com/general/74235) for more information."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! mkdir dataset && kaggle datasets download andrewmvd/face-mask-detection --unzip -p \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare dataset format\n",
    "\n",
    "convert COCO format to yolo format. below is a modified version of this [link](https://www.kaggle.com/rkuo2000/yolov5-facemask#Create-Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from xml.dom.minidom import parse\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cord_converter(size, box):\n",
    "    \"\"\"\n",
    "    convert xml annotation to darknet format coordinates\n",
    "    :param sizeï¼š [w,h]\n",
    "    :param box: anchor box coordinates [upper-left x,uppler-left y,lower-right x, lower-right y]\n",
    "    :return: converted [x,y,w,h]\n",
    "    \"\"\"\n",
    "    x1 = int(box[0])\n",
    "    y1 = int(box[1])\n",
    "    x2 = int(box[2])\n",
    "    y2 = int(box[3])\n",
    "\n",
    "    dw = np.float32(1. / int(size[0]))\n",
    "    dh = np.float32(1. / int(size[1]))\n",
    "\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    x = x1 + (w / 2)\n",
    "    y = y1 + (h / 2)\n",
    "\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def save_file(img_jpg_file_name, size, img_box):\n",
    "    save_file_name = LABELS_ROOT + '/' + img_jpg_file_name + '.txt'\n",
    "    print(save_file_name)\n",
    "    file_path = open(save_file_name, \"a+\")\n",
    "    for box in img_box:\n",
    "\n",
    "        cls_num = classes.index(box[0])\n",
    "\n",
    "        new_box = cord_converter(size, box[1:])\n",
    "\n",
    "        file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n",
    "\n",
    "    file_path.flush()\n",
    "    file_path.close()\n",
    "    \n",
    "def get_xml_data(file_path, img_xml_file):\n",
    "    img_path = file_path + '/' + img_xml_file + '.xml'\n",
    "    print(img_path)\n",
    "\n",
    "    dom = parse(img_path)\n",
    "    root = dom.documentElement\n",
    "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
    "    img_size = root.getElementsByTagName(\"size\")[0]\n",
    "    objects = root.getElementsByTagName(\"object\")\n",
    "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
    "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
    "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
    "    # print(\"img_name:\", img_name)\n",
    "    # print(\"image_info:(w,h,c)\", img_w, img_h, img_c)\n",
    "    img_box = []\n",
    "    for box in objects:\n",
    "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
    "        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
    "        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
    "        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
    "        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
    "        # print(\"box:(c,xmin,ymin,xmax,ymax)\", cls_name, x1, y1, x2, y2)\n",
    "        img_jpg_file_name = img_xml_file + '.jpg'\n",
    "        img_box.append([cls_name, x1, y1, x2, y2])\n",
    "    # print(img_box)\n",
    "\n",
    "    # test_dataset_box_feature(img_jpg_file_name, img_box)\n",
    "    save_file(img_xml_file, [img_w, img_h], img_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_ROOT = \"./dataset/\"\n",
    "IMAGE_PATH = FILE_ROOT + \"images\"  \n",
    "ANNOTATIONS_PATH = FILE_ROOT + \"annotations\"\n",
    "LABELS_ROOT = FILE_ROOT + \"labels\"\n",
    "\n",
    "classes = ['with_mask', 'without_mask', 'mask_weared_incorrect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = Path(LABELS_ROOT)\n",
    "if not labels_dir.exists():\n",
    "    print(f\"Path {labels_dir} is not exit\")\n",
    "    os.makedirs(labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(ANNOTATIONS_PATH)\n",
    "for file in files:\n",
    "    print(\"file name: \", file)\n",
    "    file_xml = file.split(\".\")\n",
    "    get_xml_data(ANNOTATIONS_PATH, file_xml[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training dataset and file\n",
    "\n",
    "copy `labels.txt` to `images` dir and make a list of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp $LABELS_ROOT/*.txt $IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = []\n",
    "for filename in os.listdir(IMAGE_PATH):\n",
    "    if filename.endswith(\".png\"):\n",
    "        image_files.append(IMAGE_PATH + \"/\" + filename)\n",
    "        \n",
    "with open(\"train.txt\", \"w\") as outfile:\n",
    "    for image in image_files:\n",
    "        outfile.write(image)\n",
    "        outfile.write(\"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with darknet\n",
    "\n",
    "download pre-trained weights `darknet53.conv.74` for yolov3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://pjreddie.com/media/files/darknet53.conv.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with yolov3. Don't execute this in notebook! but execute in a console. Use `nohup` command for long running training.\n",
    "\n",
    "> assuming darknet build is located in `../darknet`. Training will take about 1 day to complete 6000 iterations in Azure NC6 (K80).\n",
    "\n",
    "\n",
    "```\n",
    "../darknet/darknet detector train yolov3-custom.data yolov3-train.cfg darknet53.conv.74 -dont_show\n",
    "```\n",
    "\n",
    "Training result will be save in the `backup` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
